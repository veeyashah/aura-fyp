"""
"AURA"-Automated Unified Recognition for Attendance Face Recognition API - ArcFace Edition
Production-ready with 99%+ accuracy using DeepFace and ArcFace model
"""

from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from contextlib import asynccontextmanager
import cv2
import numpy as np
import base64
import io
from PIL import Image
from typing import List, Optional
import logging
from datetime import datetime
import os
import threading
import json


# ============================================================================
# LOGGING
# ============================================================================

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# ============================================================================
# DEEPFACE & MODEL SETUP
# ============================================================================

DEEPFACE_AVAILABLE = False
DEEPFACE_ERROR = None

try:
    from deepface import DeepFace
    DEEPFACE_AVAILABLE = True
    logger.info("‚úÖ DeepFace imported successfully")
except ImportError as e:
    DEEPFACE_ERROR = str(e)
    logger.warning(f"‚ö†Ô∏è DeepFace import failed: {e}")
    try:
        import face_recognition
        logger.info("‚úÖ face_recognition (dlib) available as fallback")
    except ImportError:
        logger.warning("‚ö†Ô∏è No advanced ML library available")

# Load OpenCV cascade for fallback face detection
cascade_path = cv2.data.haarcascades + 'haarcascade_frontalface_default.xml'
face_cascade = cv2.CascadeClassifier(cascade_path)
logger.info(f"‚úÖ OpenCV Haar Cascade loaded from: {cascade_path}")

# ============================================================================
# CONFIGURATION
# ============================================================================

# ArcFace uses cosine similarity (0-1 scale, higher = more similar)
# 0.68 is strict threshold equivalent to 0.35 euclidean distance
ARCFACE_THRESHOLD = 0.68

# Model dimensions for validation
EXPECTED_EMBEDDING_DIMS = [512]  # ArcFace produces 512-d embeddings

# ============================================================================
# GLOBAL STATE
# ============================================================================

known_face_encodings: List[np.ndarray] = []
known_face_names: List[str] = []
known_face_ids: List[str] = []
lock = threading.Lock()


# ============================================================================
# DATA MODELS
# ============================================================================

class TrainingRequest(BaseModel):
    student_id: str
    images: List[str]


class RecognitionRequest(BaseModel):
    image: str


class StudentData(BaseModel):
    studentId: str
    name: str
    faceEmbeddings: List[float]


class LiveRecognitionRequest(BaseModel):
    students: List[StudentData]


# ============================================================================
# LIFESPAN
# ============================================================================

@asynccontextmanager
async def lifespan(app: FastAPI):
    logger.info("\n" + "="*70)
    logger.info("üöÄ \"AURA\"-Automated Unified Recognition for Attendance Face Recognition API v3.0 (ArcFace Edition)")
    logger.info("="*70)
    logger.info(f"üì° DeepFace Status: {'‚úÖ AVAILABLE' if DEEPFACE_AVAILABLE else '‚ùå NOT AVAILABLE'}")
    logger.info(f"üéØ Threshold (Cosine): {ARCFACE_THRESHOLD} (0-1 scale, higher = stricter)")
    logger.info(f"üìä Expected Embedding Dimensions: {EXPECTED_EMBEDDING_DIMS}-d")
    logger.info("="*70 + "\n")
    yield
    logger.info("üëã API shutdown")


app = FastAPI(
    title="\"AURA\"-Automated Unified Recognition for Attendance Face Recognition",
    version="3.0",
    lifespan=lifespan
)

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


# ============================================================================
# DATA MODELS
# ============================================================================

class TrainingRequest(BaseModel):
    student_id: str
    images: List[str]


class RecognitionRequest(BaseModel):
    image: str


class StudentData(BaseModel):
    studentId: str
    name: str
    faceEmbeddings: List[float]


class LiveRecognitionRequest(BaseModel):
    students: List[StudentData]


# ============================================================================
# UTILITY FUNCTIONS
# ============================================================================

def decode_base64(b64_str: str) -> Optional[np.ndarray]:
    """Decode base64 to RGB image"""
    try:
        if "," in b64_str:
            b64_str = b64_str.split(",")[1]
        
        # Add padding if needed
        padding = len(b64_str) % 4
        if padding:
            b64_str += "=" * (4 - padding)
        
        img = Image.open(io.BytesIO(base64.b64decode(b64_str)))
        if img.mode != 'RGB':
            img = img.convert('RGB')
        
        return np.array(img)
    except Exception as e:
        logger.error(f"‚ùå Decode error: {e}")
        return None


def detect_faces_deepface(rgb_img: np.ndarray) -> List[tuple]:
    """Detect faces using DeepFace with single best detector"""
    results = []
    
    if not DEEPFACE_AVAILABLE:
        return results
    
    try:
        # Use only RetinaFace (best accuracy/speed tradeoff) - skip other detectors for speed
        detector_name = 'retinaface'
        
        try:
            # Extract faces using DeepFace
            face_objs = DeepFace.extract_faces(
                img_path=rgb_img,
                detector_backend=detector_name,
                enforce_detection=False,
                align=True
            )
            
            if face_objs and len(face_objs) > 0:
                logger.debug(f"‚úÖ {detector_name} detected {len(face_objs)} face(s)")
                
                for face_obj in face_objs:
                    facial_area = face_obj.get('facial_area', {})
                    x = facial_area.get('x', 0)
                    y = facial_area.get('y', 0)
                    w = facial_area.get('w', 0)
                    h = facial_area.get('h', 0)
                    
                    face_img = face_obj.get('face')
                    
                    if face_img is not None and face_img.size > 0:
                        if face_img.dtype != np.uint8:
                            face_img = (face_img * 255).astype(np.uint8)
                        
                        # ArcFace expects 224x224
                        face_resized = cv2.resize(face_img, (224, 224))
                        results.append((face_resized, (x, y, w, h)))
                
                if results:
                    return results
                    
        except Exception as e:
            logger.debug(f"‚ö†Ô∏è RetinaFace failed: {str(e)[:100]}")
        
        return results
        
    except Exception as e:
        logger.error(f"‚ùå DeepFace detection error: {e}")
        return []


def detect_faces_opencv(rgb_img: np.ndarray) -> List[tuple]:
    """Detect faces using OpenCV Haar Cascade (fallback)"""
    results = []
    try:
        logger.debug("üîÑ Falling back to OpenCV Haar Cascade...")
        gray = cv2.cvtColor(rgb_img, cv2.COLOR_RGB2GRAY)
        
        # Lenient parameters for detection
        faces = face_cascade.detectMultiScale(
            gray,
            scaleFactor=1.05,
            minNeighbors=3,
            minSize=(20, 20),
            flags=cv2.CASCADE_SCALE_IMAGE
        )
        
        for (x, y, w, h) in faces:
            roi = rgb_img[y:y+h, x:x+w]
            if roi.size > 0:
                roi_resized = cv2.resize(roi, (224, 224))
                results.append((roi_resized, (x, y, w, h)))
        
        if results:
            logger.info(f"‚úÖ OpenCV detected {len(results)} face(s)")
            
        return results
    except Exception as e:
        logger.debug(f"‚ö†Ô∏è OpenCV failed: {e}")
        return []


def detect_faces(rgb_img: np.ndarray) -> List[tuple]:
    """Detect faces with multiple fallbacks"""
    # Try DeepFace first (better accuracy)
    faces = detect_faces_deepface(rgb_img)
    if faces:
        return faces
    
    # Fallback to OpenCV
    faces = detect_faces_opencv(rgb_img)
    if faces:
        return faces
    
    logger.warning("‚ö†Ô∏è No faces detected by any method")
    return []


def get_embedding_deepface(face_roi: np.ndarray) -> Optional[np.ndarray]:
    """Get embedding using DeepFace ArcFace model"""
    try:
        if not DEEPFACE_AVAILABLE:
            logger.warning("‚ö†Ô∏è DeepFace not available")
            return None
        
        # ArcFace provides 512-d embeddings with superior accuracy
        result = DeepFace.represent(
            face_roi,
            model_name="ArcFace",
            enforce_detection=False,
            normalization="ArcFace"
        )
        
        if result and len(result) > 0:
            embedding = np.array(result[0]["embedding"], dtype=np.float32)
            logger.debug(f"‚úÖ ArcFace embedding: {len(embedding)}-d")
            return embedding
        
        logger.warning("‚ö†Ô∏è DeepFace returned empty result")
        return None
        
    except Exception as e:
        logger.error(f"‚ùå DeepFace embedding error: {e}")
        return None


def get_embedding(face_roi: np.ndarray) -> Optional[np.ndarray]:
    """Get embedding with fallbacks"""
    emb = get_embedding_deepface(face_roi)
    if emb is not None:
        return emb
    
    logger.warning("‚ö†Ô∏è Could not generate embedding")
    return None


def normalize_embedding(emb: np.ndarray) -> np.ndarray:
    """L2 normalize embedding"""
    norm = np.linalg.norm(emb)
    if norm > 0:
        return (emb / norm).astype(np.float32)
    return emb.astype(np.float32)


def cosine_similarity(e1: np.ndarray, e2: np.ndarray) -> float:
    """Compute cosine similarity (0-1, higher = more similar)"""
    # Normalize for cosine similarity
    e1_norm = e1 / (np.linalg.norm(e1) + 1e-10)
    e2_norm = e2 / (np.linalg.norm(e2) + 1e-10)
    
    similarity = float(np.dot(e1_norm, e2_norm))
    
    # Clamp to [0, 1] range for cosine similarity
    return max(0.0, min(1.0, similarity))




# ============================================================================
# ENDPOINTS
# ============================================================================

@app.get("/health")
async def health():
    """Health check endpoint"""
    return {
        "status": "OK",
        "model": "ArcFace (DeepFace)" if DEEPFACE_AVAILABLE else "OpenCV (Fallback)",
        "deepface_available": DEEPFACE_AVAILABLE,
        "deepface_error": DEEPFACE_ERROR,
        "loaded_students": len(known_face_names),
        "embedding_dimension": 512,
        "version": "3.0"
    }


@app.get("/status")
async def status():
    """Get detailed status including loaded students"""
    with lock:
        faces = []
        for i in range(len(known_face_names)):
            faces.append({
                "id": i,
                "name": known_face_names[i],
                "student_id": known_face_ids[i] if i < len(known_face_ids) else "",
                "embedding_dim": len(known_face_encodings[i]) if i < len(known_face_encodings) else 0
            })
        
        return {
            "status": "ready" if known_face_names else "empty",
            "students_loaded": len(known_face_names),
            "embedding_dimension": 512,
            "threshold": ARCFACE_THRESHOLD,
            "faces": faces,
            "deepface_status": "‚úÖ Available" if DEEPFACE_AVAILABLE else "‚ùå Not Available"
        }


@app.post("/load-students")
async def load_students(req: LiveRecognitionRequest):
    """Load student embeddings into memory"""
    global known_face_encodings, known_face_names, known_face_ids
    
    try:
        with lock:
            known_face_encodings.clear()
            known_face_names.clear()
            known_face_ids.clear()
            
            logger.info(f"üì• Loading {len(req.students)} students...")
            
            loaded = 0
            skipped = 0
            errors = []
            
            for student in req.students:
                try:
                    if not student.faceEmbeddings or len(student.faceEmbeddings) == 0:
                        skipped += 1
                        errors.append(f"{student.name}: No embeddings")
                        continue
                    
                    # Validate embedding dimension
                    if len(student.faceEmbeddings) not in EXPECTED_EMBEDDING_DIMS:
                        skipped += 1
                        errors.append(f"{student.name}: Invalid dimension {len(student.faceEmbeddings)}d (expected {EXPECTED_EMBEDDING_DIMS[0]}d)")
                        continue
                    
                    emb = np.array(student.faceEmbeddings, dtype=np.float32)
                    emb = normalize_embedding(emb)
                    
                    known_face_encodings.append(emb)
                    known_face_names.append(student.name)
                    known_face_ids.append(student.studentId)
                    loaded += 1
                    
                except Exception as e:
                    skipped += 1
                    errors.append(f"{student.name}: {str(e)[:50]}")
            
            logger.info(f"‚úÖ Loaded {loaded} students, skipped {skipped}")
            if errors and len(errors) <= 5:
                for err in errors[:5]:
                    logger.debug(f"   - {err}")
            
            return {
                "success": True,
                "loaded_count": loaded,
                "skipped_count": skipped,
                "total_requested": len(req.students),
                "errors": errors[:10] if errors else []
            }
    except Exception as e:
        logger.error(f"‚ùå Load students error: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/train")
async def train(req: TrainingRequest):
    """Train: Extract embeddings from images (sequential, stable processing)"""
    try:
        logger.info(f"üéì Training {req.student_id} with {len(req.images)} images")
        
        if len(req.images) < 3:
            raise HTTPException(400, "Minimum 3 images required for training")
        
        embeddings = []
        
        # Process images sequentially for maximum stability
        for idx, img_b64 in enumerate(req.images[:50]):
            try:
                rgb = decode_base64(img_b64)
                if rgb is None:
                    logger.debug(f"Image {idx+1}: Failed to decode")
                    continue
                
                # Detect face
                faces = detect_faces(rgb)
                if not faces:
                    logger.debug(f"Image {idx+1}: No faces detected")
                    continue
                
                # Get embedding from first face
                emb = get_embedding(faces[0][0])
                if emb is not None:
                    embeddings.append(normalize_embedding(emb))
                else:
                    logger.debug(f"Image {idx+1}: Failed to get embedding")
                    
            except Exception as e:
                logger.debug(f"Image {idx+1} error: {str(e)[:30]}")
                continue
        
        if len(embeddings) < 3:
            logger.error(f"‚ùå Only {len(embeddings)} valid faces from {len(req.images)} images")
            raise HTTPException(400, f"Need at least 3 valid faces, got {len(embeddings)}")
        
        # Average embeddings
        avg_emb = np.mean(embeddings, axis=0).astype(np.float32)
        avg_emb = normalize_embedding(avg_emb)
        
        logger.info(f"‚úÖ Training complete: {len(embeddings)} faces processed")
        
        return {
            "success": True,
            "embedding": avg_emb.tolist(),
            "faces_processed": len(embeddings),
            "embedding_dimension": len(avg_emb)
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"‚ùå Training error: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/recognize")
async def recognize(req: RecognitionRequest):
    """Recognize faces in image"""
    try:
        logger.info(f"üîç Recognition request (loaded: {len(known_face_names)} students)")
        
        with lock:
            if not known_face_encodings:
                logger.warning("‚ö†Ô∏è No students loaded in memory")
                return {
                    "success": True,
                    "faces": [],
                    "loaded_students": 0,
                    "note": "No trained students loaded"
                }
            
            # Decode image
            rgb = decode_base64(req.image)
            if rgb is None:
                logger.error("‚ùå Failed to decode image")
                return {"success": False, "faces": [], "error": "Decode failed"}
            
            logger.debug(f"‚úÖ Image decoded: {rgb.shape}")
            
            # Detect faces
            faces = detect_faces(rgb)
            if not faces:
                logger.debug("‚ÑπÔ∏è No faces detected")
                return {
                    "success": True,
                    "faces": [],
                    "loaded_students": len(known_face_names),
                    "note": "No faces detected in image"
                }
            
            logger.info(f"üë§ Detected {len(faces)} face(s)")
            results = []
            
            # Process each face
            for idx, (face_roi, box) in enumerate(faces):
                try:
                    # Get embedding
                    emb = get_embedding(face_roi)
                    if emb is None:
                        logger.debug(f"Face {idx+1}: Failed to get embedding")
                        continue
                    
                    emb = normalize_embedding(emb)
                    
                    # Find best match
                    max_similarity = -1.0
                    best_idx = -1
                    
                    for i, known_emb in enumerate(known_face_encodings):
                        similarity = cosine_similarity(emb, known_emb)
                        if similarity > max_similarity:
                            max_similarity = similarity
                            best_idx = i
                    
                    # Check against threshold
                    recognized = max_similarity >= ARCFACE_THRESHOLD
                    
                    # Convert to distance for frontend compatibility
                    distance = float(1.0 - max_similarity)
                    
                    result = {
                        "name": known_face_names[best_idx] if recognized else "Unknown",
                        "student_id": known_face_ids[best_idx] if recognized else "",
                        "similarity": float(max_similarity),
                        "distance": distance,
                        "recognized": recognized,
                        "confidence": float(max_similarity) if recognized else 0.0,
                        "box": [int(box[0]), int(box[1]), int(box[0] + box[2]), int(box[1] + box[3])]
                    }
                    
                    results.append(result)
                    
                    if recognized:
                        logger.info(f"‚úÖ Face {idx+1}: {known_face_names[best_idx]} (similarity: {max_similarity:.3f})")
                    else:
                        logger.debug(f"‚ÑπÔ∏è Face {idx+1}: No match (best={known_face_names[best_idx]}, {max_similarity:.3f})")
                        
                except Exception as e:
                    logger.error(f"Face {idx+1}: {e}")
                    continue
            
            return {
                "success": True,
                "faces": results,
                "timestamp": datetime.now().isoformat(),
                "loaded_students": len(known_face_names)
            }
            
    except Exception as e:
        logger.error(f"‚ùå Recognition error: {e}")
        return {"success": False, "faces": [], "error": str(e)}


@app.post("/test-detection")
async def test_detection(req: RecognitionRequest):
    """Test face detection only"""
    try:
        logger.info("üß™ Testing face detection...")
        
        rgb = decode_base64(req.image)
        if rgb is None:
            return {"success": False, "error": "Failed to decode image"}
        
        logger.info(f"‚úÖ Image decoded: {rgb.shape}")
        
        # Detect faces
        faces = detect_faces(rgb)
        
        if not faces:
            logger.warning("‚ö†Ô∏è No faces detected")
            return {
                "success": True,
                "faces_detected": 0,
                "message": "No faces detected. Try: better lighting, face camera directly, adjust distance"
            }
        
        logger.info(f"‚úÖ Detected {len(faces)} face(s)")
        
        face_boxes = []
        for idx, (roi, box) in enumerate(faces):
            x, y, w, h = box
            face_boxes.append({
                "index": idx,
                "box": [int(x), int(y), int(x + w), int(y + h)],
                "size": f"{w}x{h}px"
            })
        
        return {
            "success": True,
            "faces_detected": len(faces),
            "faces": face_boxes,
            "message": f"Successfully detected {len(faces)} face(s)"
        }
        
    except Exception as e:
        logger.error(f"‚ùå Detection test error: {e}")
        return {"success": False, "error": str(e)}


# ============================================================================
# STARTUP
# ============================================================================

if __name__ == "__main__":
    import uvicorn
    
    print("\n" + "="*70)
    print("Starting \"AURA\"-Automated Unified Recognition for Attendance Face Recognition API v3.0")
    print("="*70)
    print("üìç Address: http://0.0.0.0:8000")
    print("üìö Docs: http://localhost:8000/docs")
    print("="*70 + "\n")
    
    uvicorn.run(app, host="0.0.0.0", port=8000, log_level="info")
